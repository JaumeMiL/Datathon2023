{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DATATHON 2023: NTT-DATA CHALLENGE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Requirements**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 1)) (1.26.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: pandas in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 2)) (2.1.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 3)) (3.8.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 4)) (0.12.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: statsmodels in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 6)) (0.14.0)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 7)) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (3.1.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.11.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (3.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from statsmodels->-r requirements.txt (line 6)) (0.5.3)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openpyxl->-r requirements.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: six in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from patsy>=0.5.2->statsmodels->-r requirements.txt (line 6)) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Main Program**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODIGO</th>\n",
       "      <th>FECHAPEDIDO</th>\n",
       "      <th>NUMERO</th>\n",
       "      <th>REFERENCIA</th>\n",
       "      <th>CANTIDADCOMPRA</th>\n",
       "      <th>UNIDADESCONSUMOCONTENIDAS</th>\n",
       "      <th>PRECIO</th>\n",
       "      <th>IMPORTELINEA</th>\n",
       "      <th>TIPOCOMPRA</th>\n",
       "      <th>ORIGEN</th>\n",
       "      <th>TGL</th>\n",
       "      <th>PRODUCTO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E99808</td>\n",
       "      <td>01/01/23</td>\n",
       "      <td>1595724/23</td>\n",
       "      <td>178567.1</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>62.590000</td>\n",
       "      <td>375.540000</td>\n",
       "      <td>Compra menor</td>\n",
       "      <td>1-2-60</td>\n",
       "      <td>TRANSITO</td>\n",
       "      <td>APOSITO DE FIBRAS DE POLIACRILATO C/PLATA-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B41691</td>\n",
       "      <td>01/02/16</td>\n",
       "      <td>72714/16</td>\n",
       "      <td>400403</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>102.803729</td>\n",
       "      <td>411.214916</td>\n",
       "      <td>Compra menor</td>\n",
       "      <td>0-10-1</td>\n",
       "      <td>ALMACENABLE</td>\n",
       "      <td>SOLUCION P/ LIMPIEZA Y DESCONTAMINACION DE HER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E64543</td>\n",
       "      <td>01/02/16</td>\n",
       "      <td>71961/16</td>\n",
       "      <td>403770</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>48.400000</td>\n",
       "      <td>Compra menor</td>\n",
       "      <td>0-4-111</td>\n",
       "      <td>TRANSITO</td>\n",
       "      <td>APOSITO DE HIDROFIBRA  / CINTA-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E65007</td>\n",
       "      <td>01/02/16</td>\n",
       "      <td>72773/16</td>\n",
       "      <td>20415</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>215.325000</td>\n",
       "      <td>430.650000</td>\n",
       "      <td>Concurso</td>\n",
       "      <td>0-10-1</td>\n",
       "      <td>ALMACENABLE</td>\n",
       "      <td>APOSITO DE ESPUMA POLIURETANO / SACRO-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E64911</td>\n",
       "      <td>01/02/17</td>\n",
       "      <td>86159/17</td>\n",
       "      <td>20701</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>Concurso</td>\n",
       "      <td>0-6-1</td>\n",
       "      <td>ALMACENABLE</td>\n",
       "      <td>APOSITO C/ CARBON Y PLATA-6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CODIGO FECHAPEDIDO      NUMERO REFERENCIA  CANTIDADCOMPRA  \\\n",
       "0  E99808    01/01/23  1595724/23   178567.1              60   \n",
       "1  B41691    01/02/16    72714/16     400403              40   \n",
       "2  E64543    01/02/16    71961/16     403770              20   \n",
       "3  E65007    01/02/16    72773/16      20415             100   \n",
       "4  E64911    01/02/17    86159/17      20701             300   \n",
       "\n",
       "   UNIDADESCONSUMOCONTENIDAS      PRECIO  IMPORTELINEA    TIPOCOMPRA   ORIGEN  \\\n",
       "0                         10   62.590000    375.540000  Compra menor   1-2-60   \n",
       "1                         10  102.803729    411.214916  Compra menor   0-10-1   \n",
       "2                          5   12.100000     48.400000  Compra menor  0-4-111   \n",
       "3                         50  215.325000    430.650000      Concurso   0-10-1   \n",
       "4                        300  792.000000    792.000000      Concurso    0-6-1   \n",
       "\n",
       "           TGL                                           PRODUCTO  \n",
       "0     TRANSITO        APOSITO DE FIBRAS DE POLIACRILATO C/PLATA-3  \n",
       "1  ALMACENABLE  SOLUCION P/ LIMPIEZA Y DESCONTAMINACION DE HER...  \n",
       "2     TRANSITO                  APOSITO DE HIDROFIBRA  / CINTA-18  \n",
       "3  ALMACENABLE           APOSITO DE ESPUMA POLIURETANO / SACRO-11  \n",
       "4  ALMACENABLE                        APOSITO C/ CARBON Y PLATA-6  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../assets/consumo_material_clean.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODIGO</th>\n",
       "      <th>FECHAPEDIDO</th>\n",
       "      <th>NUMERO</th>\n",
       "      <th>REFERENCIA</th>\n",
       "      <th>CANTIDADCOMPRA</th>\n",
       "      <th>UNIDADESCONSUMOCONTENIDAS</th>\n",
       "      <th>PRECIO</th>\n",
       "      <th>IMPORTELINEA</th>\n",
       "      <th>TIPOCOMPRA</th>\n",
       "      <th>TGL</th>\n",
       "      <th>PRODUCTO</th>\n",
       "      <th>REGION</th>\n",
       "      <th>HOSPITAL</th>\n",
       "      <th>DEPARTAMENTO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E99808</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>1595724/23</td>\n",
       "      <td>178567.1</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>62.590000</td>\n",
       "      <td>375.540000</td>\n",
       "      <td>Compra menor</td>\n",
       "      <td>TRANSITO</td>\n",
       "      <td>APOSITO DE FIBRAS DE POLIACRILATO C/PLATA-3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B41691</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>72714/16</td>\n",
       "      <td>400403</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>102.803729</td>\n",
       "      <td>411.214916</td>\n",
       "      <td>Compra menor</td>\n",
       "      <td>ALMACENABLE</td>\n",
       "      <td>SOLUCION P/ LIMPIEZA Y DESCONTAMINACION DE HER...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E64543</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>71961/16</td>\n",
       "      <td>403770</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>48.400000</td>\n",
       "      <td>Compra menor</td>\n",
       "      <td>TRANSITO</td>\n",
       "      <td>APOSITO DE HIDROFIBRA  / CINTA-18</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E65007</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>72773/16</td>\n",
       "      <td>20415</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>215.325000</td>\n",
       "      <td>430.650000</td>\n",
       "      <td>Concurso</td>\n",
       "      <td>ALMACENABLE</td>\n",
       "      <td>APOSITO DE ESPUMA POLIURETANO / SACRO-11</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E64911</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>86159/17</td>\n",
       "      <td>20701</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>Concurso</td>\n",
       "      <td>ALMACENABLE</td>\n",
       "      <td>APOSITO C/ CARBON Y PLATA-6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CODIGO FECHAPEDIDO      NUMERO REFERENCIA  CANTIDADCOMPRA  \\\n",
       "0  E99808  2023-01-01  1595724/23   178567.1              60   \n",
       "1  B41691  2016-02-01    72714/16     400403              40   \n",
       "2  E64543  2016-02-01    71961/16     403770              20   \n",
       "3  E65007  2016-02-01    72773/16      20415             100   \n",
       "4  E64911  2017-02-01    86159/17      20701             300   \n",
       "\n",
       "   UNIDADESCONSUMOCONTENIDAS      PRECIO  IMPORTELINEA    TIPOCOMPRA  \\\n",
       "0                         10   62.590000    375.540000  Compra menor   \n",
       "1                         10  102.803729    411.214916  Compra menor   \n",
       "2                          5   12.100000     48.400000  Compra menor   \n",
       "3                         50  215.325000    430.650000      Concurso   \n",
       "4                        300  792.000000    792.000000      Concurso   \n",
       "\n",
       "           TGL                                           PRODUCTO REGION  \\\n",
       "0     TRANSITO        APOSITO DE FIBRAS DE POLIACRILATO C/PLATA-3      1   \n",
       "1  ALMACENABLE  SOLUCION P/ LIMPIEZA Y DESCONTAMINACION DE HER...      0   \n",
       "2     TRANSITO                  APOSITO DE HIDROFIBRA  / CINTA-18      0   \n",
       "3  ALMACENABLE           APOSITO DE ESPUMA POLIURETANO / SACRO-11      0   \n",
       "4  ALMACENABLE                        APOSITO C/ CARBON Y PLATA-6      0   \n",
       "\n",
       "  HOSPITAL DEPARTAMENTO  \n",
       "0        2           60  \n",
       "1       10            1  \n",
       "2        4          111  \n",
       "3       10            1  \n",
       "4        6            1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with NaN values\n",
    "df = df.dropna()\n",
    "\n",
    "# Date format\n",
    "df['FECHAPEDIDO'] = pd.to_datetime(df['FECHAPEDIDO'], format='%d/%m/%y')\n",
    "\n",
    "# Split \"ORIGEN\" into \"REGION\", \"HOSPITAL\" and \"DEPARTAMENTO\"\n",
    "df['ORIGEN'] = df['ORIGEN'].str.replace('--', '-')\n",
    "df[['REGION', 'HOSPITAL', 'DEPARTAMENTO']] = df['ORIGEN'].str.split('-', expand=True)\n",
    "df = df.drop([\"ORIGEN\"], axis=1)\n",
    "\n",
    "# Categorical variables\n",
    "categorical = ['CODIGO', 'PRODUCTO', 'NUMERO', 'REFERENCIA', 'TIPOCOMPRA', 'REGION', 'HOSPITAL', 'DEPARTAMENTO', 'TGL']\n",
    "df[categorical] = df[categorical].astype('category')\n",
    "\n",
    "# Numeric variables\n",
    "numerical_int = ['CANTIDADCOMPRA', 'UNIDADESCONSUMOCONTENIDAS']\n",
    "numerical_float = ['PRECIO', 'IMPORTELINEA']\n",
    "df[numerical_float] = df[numerical_float].astype('float')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New dataset with the important variables to train/predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODIGO                       category\n",
      "NUMERO                       category\n",
      "REFERENCIA                   category\n",
      "CANTIDADCOMPRA                  int64\n",
      "UNIDADESCONSUMOCONTENIDAS       int64\n",
      "PRECIO                        float64\n",
      "IMPORTELINEA                  float64\n",
      "TIPOCOMPRA                   category\n",
      "TGL                          category\n",
      "PRODUCTO                     category\n",
      "REGION                       category\n",
      "HOSPITAL                     category\n",
      "DEPARTAMENTO                 category\n",
      "MES                             int32\n",
      "AÑO                             int32\n",
      "PRECIOUNIDAD                  float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODIGO</th>\n",
       "      <th>NUMERO</th>\n",
       "      <th>REFERENCIA</th>\n",
       "      <th>CANTIDADCOMPRA</th>\n",
       "      <th>UNIDADESCONSUMOCONTENIDAS</th>\n",
       "      <th>PRECIO</th>\n",
       "      <th>IMPORTELINEA</th>\n",
       "      <th>TIPOCOMPRA</th>\n",
       "      <th>TGL</th>\n",
       "      <th>PRODUCTO</th>\n",
       "      <th>REGION</th>\n",
       "      <th>HOSPITAL</th>\n",
       "      <th>DEPARTAMENTO</th>\n",
       "      <th>MES</th>\n",
       "      <th>AÑO</th>\n",
       "      <th>PRECIOUNIDAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E99808</td>\n",
       "      <td>1595724/23</td>\n",
       "      <td>178567.1</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>62.590000</td>\n",
       "      <td>375.540000</td>\n",
       "      <td>Compra menor</td>\n",
       "      <td>TRANSITO</td>\n",
       "      <td>APOSITO DE FIBRAS DE POLIACRILATO C/PLATA-3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>6.259000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B41691</td>\n",
       "      <td>72714/16</td>\n",
       "      <td>400403</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>102.803729</td>\n",
       "      <td>411.214916</td>\n",
       "      <td>Compra menor</td>\n",
       "      <td>ALMACENABLE</td>\n",
       "      <td>SOLUCION P/ LIMPIEZA Y DESCONTAMINACION DE HER...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>10.280373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E64543</td>\n",
       "      <td>71961/16</td>\n",
       "      <td>403770</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>48.400000</td>\n",
       "      <td>Compra menor</td>\n",
       "      <td>TRANSITO</td>\n",
       "      <td>APOSITO DE HIDROFIBRA  / CINTA-18</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>2.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E65007</td>\n",
       "      <td>72773/16</td>\n",
       "      <td>20415</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>215.325000</td>\n",
       "      <td>430.650000</td>\n",
       "      <td>Concurso</td>\n",
       "      <td>ALMACENABLE</td>\n",
       "      <td>APOSITO DE ESPUMA POLIURETANO / SACRO-11</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>4.306500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E64911</td>\n",
       "      <td>86159/17</td>\n",
       "      <td>20701</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>Concurso</td>\n",
       "      <td>ALMACENABLE</td>\n",
       "      <td>APOSITO C/ CARBON Y PLATA-6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>2.640000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CODIGO      NUMERO REFERENCIA  CANTIDADCOMPRA  UNIDADESCONSUMOCONTENIDAS  \\\n",
       "0  E99808  1595724/23   178567.1              60                         10   \n",
       "1  B41691    72714/16     400403              40                         10   \n",
       "2  E64543    71961/16     403770              20                          5   \n",
       "3  E65007    72773/16      20415             100                         50   \n",
       "4  E64911    86159/17      20701             300                        300   \n",
       "\n",
       "       PRECIO  IMPORTELINEA    TIPOCOMPRA          TGL  \\\n",
       "0   62.590000    375.540000  Compra menor     TRANSITO   \n",
       "1  102.803729    411.214916  Compra menor  ALMACENABLE   \n",
       "2   12.100000     48.400000  Compra menor     TRANSITO   \n",
       "3  215.325000    430.650000      Concurso  ALMACENABLE   \n",
       "4  792.000000    792.000000      Concurso  ALMACENABLE   \n",
       "\n",
       "                                            PRODUCTO REGION HOSPITAL  \\\n",
       "0        APOSITO DE FIBRAS DE POLIACRILATO C/PLATA-3      1        2   \n",
       "1  SOLUCION P/ LIMPIEZA Y DESCONTAMINACION DE HER...      0       10   \n",
       "2                  APOSITO DE HIDROFIBRA  / CINTA-18      0        4   \n",
       "3           APOSITO DE ESPUMA POLIURETANO / SACRO-11      0       10   \n",
       "4                        APOSITO C/ CARBON Y PLATA-6      0        6   \n",
       "\n",
       "  DEPARTAMENTO  MES   AÑO  PRECIOUNIDAD  \n",
       "0           60    1  2023      6.259000  \n",
       "1            1    2  2016     10.280373  \n",
       "2          111    2  2016      2.420000  \n",
       "3            1    2  2016      4.306500  \n",
       "4            1    2  2017      2.640000  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df[['PRODUCTO', 'FECHAPEDIDO', 'TIPOCOMPRA', 'REGION', 'HOSPITAL', 'DEPARTAMENTO', 'TGL', 'CANTIDADCOMPRA', 'UNIDADESCONSUMOCONTENIDAS', 'PRECIO', 'IMPORTELINEA']].copy()\n",
    "\n",
    "new_df['MES'] = new_df['FECHAPEDIDO'].dt.month\n",
    "new_df['AÑO'] = new_df['FECHAPEDIDO'].dt.year\n",
    "new_df = new_df.drop('FECHAPEDIDO', axis=1)\n",
    "\n",
    "new_df['PRECIOUNIDAD'] = new_df['IMPORTELINEA'] / new_df['CANTIDADCOMPRA']\n",
    "\n",
    "print(new_df.dtypes)\n",
    "\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by product, year, month and type of purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.groupby(['AÑO', 'MES', 'PRODUCTO', 'HOSPITAL', 'TIPOCOMPRA', 'TGL'], observed=True).agg({'CANTIDADCOMPRA': 'sum', 'UNIDADESCONSUMOCONTENIDAS': 'mean', 'PRECIO': 'mean', 'IMPORTELINEA': 'sum', 'PRECIOUNIDAD': 'mean'}).reset_index()\n",
    "\n",
    "new_df.drop(['UNIDADESCONSUMOCONTENIDAS', 'PRECIO', 'IMPORTELINEA', 'PRECIOUNIDAD'], axis=1, inplace=True)\n",
    "\n",
    "new_df.to_csv('../assets/new_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_year = 2023\n",
    "train = new_df.loc[new_df['AÑO'] < split_year]\n",
    "test = new_df.loc[new_df['AÑO'] >= split_year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('../assets/train.csv', index=False)\n",
    "test.to_csv('../assets/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución original de clases: Counter({200: 84, 100: 77, 10: 71, 5: 40, 300: 37, 20: 37, 60: 35, 30: 29, 1000: 28, 600: 25, 12: 25, 50: 24, 120: 23, 150: 23, 40: 22, 1200: 19, 180: 19, 70: 19, 350: 18, 80: 17, 400: 17, 15: 16, 900: 14, 25: 14, 140: 13, 2000: 13, 110: 13, 4: 13, 3000: 12, 6: 12, 160: 11, 130: 11, 700: 11, 800: 10, 24: 9, 320: 9, 240: 9, 5000: 9, 3: 9, 90: 9, 7000: 8, 210: 8, 290: 8, 3200: 8, 1008: 7, 220: 7, 4000: 7, 1800: 7, 500: 7, 35: 7, 7: 7, 560: 7, 450: 6, 1500: 6, 360: 6, 380: 6, 260: 5, 2700: 5, 9: 5, 280: 5, 250: 5, 170: 5, 310: 5, 1280: 5, 270: 4, 420: 4, 3400: 4, 45: 4, 135: 4, 72: 4, 3300: 4, 8: 4, 1250: 4, 440: 4, 2: 4, 75: 3, 650: 3, 330: 3, 460: 3, 2016: 3, 530: 3, 1700: 3, 1600: 3, 2500: 3, 340: 3, 65: 3, 84: 3, 480: 3, 1120: 3, 2240: 3, 230: 3, 1090: 2, 195: 2, 370: 2, 850: 2, 48: 2, 1030: 2, 1220: 2, 1100: 2, 36: 2, 780: 2, 1260: 2, 540: 2, 630: 2, 750: 2, 3600: 2, 108: 2, 430: 2, 1550: 2, 1300: 2, 6300: 2, 2750: 2, 115: 2, 435: 2, 1350: 2, 8000: 2, 32: 2, 1760: 2, 1470: 2, 2200: 2, 6000: 2, 640: 2, 190: 2, 940: 2, 1650: 2, 930: 2, 501: 2, 1430: 2, 1050: 2, 520: 2, 1060: 2, 3840: 2, 10000: 2, 1170: 2, 525: 1, 710: 1, 141: 1, 669: 1, 6600: 1, 470: 1, 510: 1, 414: 1, 2540: 1, 855: 1, 55: 1, 132: 1, 444: 1, 1640: 1, 1560: 1, 14: 1, 1940: 1, 837: 1, 663: 1, 255: 1, 950: 1, 1235: 1, 910: 1, 2100: 1, 2050: 1, 2600: 1, 1370: 1, 1340: 1, 1145: 1, 1680: 1, 1755: 1, 432: 1, 81: 1, 575: 1, 1580: 1, 2645: 1, 570: 1, 1310: 1, 4200: 1, 16: 1, 2310: 1, 1360: 1, 410: 1, 1105: 1, 2268: 1, 1134: 1, 477: 1, 355: 1, 2130: 1, 4500: 1, 1435: 1, 1480: 1, 1620: 1, 990: 1, 2460: 1, 3750: 1, 920: 1, 580: 1, 1671: 1, 870: 1, 441: 1, 335: 1, 1870: 1, 2960: 1, 2235: 1, 515: 1, 3540: 1, 1040: 1, 720: 1, 1140: 1, 1240: 1, 265: 1, 1131: 1, 615: 1, 3680: 1, 235: 1, 1330: 1, 1460: 1, 3390: 1, 4800: 1, 880: 1, 1420: 1, 670: 1, 145: 1, 867: 1, 504: 1, 175: 1, 1830: 1, 2720: 1, 1415: 1, 740: 1, 1110: 1, 3220: 1, 1392: 1, 438: 1, 85: 1, 1770: 1, 3940: 1, 1025: 1, 345: 1, 610: 1, 5120: 1, 3870: 1, 1450: 1, 3500: 1, 96: 1, 1070: 1, 1130: 1, 970: 1, 702: 1, 474: 1, 215: 1, 3260: 1, 1045: 1, 2560: 1, 6400: 1, 2800: 1, 4160: 1, 63: 1, 1080: 1, 125: 1, 993: 1, 411: 1, 3280: 1, 315: 1, 625: 1, 635: 1, 960: 1, 2010: 1, 4120: 1, 5400: 1, 18: 1, 890: 1})\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'BOMBA DE UN SOLO USO / TERAPIA PRESIÓN NEGATIVA-40'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Cai Selvas Sala\\GIA_UPC\\Personal\\DatathonFME\\DatathonFME_2023\\Datathon2023\\src\\main.ipynb Cell 19\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Cai%20Selvas%20Sala/GIA_UPC/Personal/DatathonFME/DatathonFME_2023/Datathon2023/src/main.ipynb#X24sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDistribución original de clases:\u001b[39m\u001b[39m\"\u001b[39m, Counter(y_train))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Cai%20Selvas%20Sala/GIA_UPC/Personal/DatathonFME/DatathonFME_2023/Datathon2023/src/main.ipynb#X24sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m smote \u001b[39m=\u001b[39m SMOTE(random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Cai%20Selvas%20Sala/GIA_UPC/Personal/DatathonFME/DatathonFME_2023/Datathon2023/src/main.ipynb#X24sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m X_train_smote, y_train_smote \u001b[39m=\u001b[39m smote\u001b[39m.\u001b[39;49mfit_resample(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Cai%20Selvas%20Sala/GIA_UPC/Personal/DatathonFME/DatathonFME_2023/Datathon2023/src/main.ipynb#X24sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDistribución de clases después de SMOTE:\u001b[39m\u001b[39m\"\u001b[39m, Counter(y_train_smote))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Cai%20Selvas%20Sala/GIA_UPC/Personal/DatathonFME/DatathonFME_2023/Datathon2023/src/main.ipynb#X24sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# Creating a pipeline\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Cai Selvas Sala\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \n\u001b[0;32m    189\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m--> 208\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit_resample(X, y)\n",
      "File \u001b[1;32mc:\\Users\\Cai Selvas Sala\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\base.py:112\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    106\u001b[0m X, y, binarize_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_X_y(X, y)\n\u001b[0;32m    108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_strategy_ \u001b[39m=\u001b[39m check_sampling_strategy(\n\u001b[0;32m    109\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_strategy, y, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampling_type\n\u001b[0;32m    110\u001b[0m )\n\u001b[1;32m--> 112\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_resample(X, y)\n\u001b[0;32m    114\u001b[0m y_ \u001b[39m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m     label_binarize(output[\u001b[39m1\u001b[39m], classes\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39munique(y)) \u001b[39mif\u001b[39;00m binarize_y \u001b[39melse\u001b[39;00m output[\u001b[39m1\u001b[39m]\n\u001b[0;32m    116\u001b[0m )\n\u001b[0;32m    118\u001b[0m X_, y_ \u001b[39m=\u001b[39m arrays_transformer\u001b[39m.\u001b[39mtransform(output[\u001b[39m0\u001b[39m], y_)\n",
      "File \u001b[1;32mc:\\Users\\Cai Selvas Sala\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:363\u001b[0m, in \u001b[0;36mSMOTE._fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    360\u001b[0m target_class_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mflatnonzero(y \u001b[39m==\u001b[39m class_sample)\n\u001b[0;32m    361\u001b[0m X_class \u001b[39m=\u001b[39m _safe_indexing(X, target_class_indices)\n\u001b[1;32m--> 363\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnn_k_\u001b[39m.\u001b[39;49mfit(X_class)\n\u001b[0;32m    364\u001b[0m nns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnn_k_\u001b[39m.\u001b[39mkneighbors(X_class, return_distance\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)[:, \u001b[39m1\u001b[39m:]\n\u001b[0;32m    365\u001b[0m X_new, y_new \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_samples(\n\u001b[0;32m    366\u001b[0m     X_class, y\u001b[39m.\u001b[39mdtype, class_sample, X_class, nns, n_samples, \u001b[39m1.0\u001b[39m\n\u001b[0;32m    367\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Cai Selvas Sala\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Cai Selvas Sala\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_unsupervised.py:178\u001b[0m, in \u001b[0;36mNearestNeighbors.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[39m@_fit_context\u001b[39m(\n\u001b[0;32m    158\u001b[0m     \u001b[39m# NearestNeighbors.metric is not validated yet\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    160\u001b[0m )\n\u001b[0;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    162\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit the nearest neighbors estimator from the training dataset.\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \n\u001b[0;32m    164\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[39m        The fitted nearest neighbors estimator.\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 178\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n",
      "File \u001b[1;32mc:\\Users\\Cai Selvas Sala\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:498\u001b[0m, in \u001b[0;36mNeighborsBase._fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    497\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(X, (KDTree, BallTree, NeighborsBase)):\n\u001b[1;32m--> 498\u001b[0m         X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    500\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_algorithm_metric()\n\u001b[0;32m    501\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetric_params \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Cai Selvas Sala\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    602\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    603\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 604\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    605\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    606\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\Cai Selvas Sala\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:917\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    916\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 917\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    918\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    919\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    920\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    921\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Cai Selvas Sala\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    378\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39marray(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    379\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39masarray(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    382\u001b[0m \u001b[39m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'BOMBA DE UN SOLO USO / TERAPIA PRESIÓN NEGATIVA-40'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Selecting categorical and numerical columns\n",
    "categorical_cols = ['TIPOCOMPRA', 'PRODUCTO', 'HOSPITAL', 'TGL']\n",
    "numerical_cols = ['AÑO', 'MES']\n",
    "\n",
    "# Creating transformers for numerical and categorical columns\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Bundling transformers into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "X_train = train.drop('CANTIDADCOMPRA', axis=1)\n",
    "y_train = train['CANTIDADCOMPRA']\n",
    "\n",
    "# Preparing the testing data\n",
    "X_test = test.drop('CANTIDADCOMPRA', axis=1)\n",
    "y_test = test['CANTIDADCOMPRA']\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# Creating a pipeline\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('regressor', RandomForestRegressor(random_state=42))])\n",
    "\n",
    "# Hyperparameters to tune\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [50, 100, 150],\n",
    "    'regressor__max_depth': [10, 20, 30, None]\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid_search = GridSearchCV(model, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fitting the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Best model from grid search\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Predicting with the best model\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "print(f'MSE with Random Forest: {mse_rf}')\n",
    "print(f'RMSE with Random Forest: {rmse_rf}')\n",
    "print(f'R2 score with Random Forest: {r2_rf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: XGBRegressor\n",
      "MSE Train: 170574.9051897159\n",
      "MSE Test: 882126.9163475028\n",
      "MAE Test: 407.8388120599573\n",
      "R2 Score: 0.5274249621102094\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Separar características y variable objetivo\n",
    "X_train = train.drop('CANTIDADCOMPRA', axis=1)\n",
    "y_train = train['CANTIDADCOMPRA']\n",
    "X_test = test.drop('CANTIDADCOMPRA', axis=1)\n",
    "y_test = test['CANTIDADCOMPRA']\n",
    "\n",
    "# Preprocesamiento\n",
    "categorical_features = ['PRODUCTO', 'HOSPITAL', 'TIPOCOMPRA', 'TGL']\n",
    "numerical_features = ['AÑO', 'MES']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "models_params = {\n",
    "\t\"XGBRegressor\": {\n",
    "\t\t\"model\": XGBRegressor(random_state=0),\n",
    "\t\t\"params\": {\"regressor__n_estimators\": [50, 100, 200], \"regressor__learning_rate\": [0.01, 0.1], \"regressor__max_depth\": [3, 5, 10, 20]}\n",
    "\t}\n",
    "}\n",
    "\n",
    "# Función para evaluar los modelos\n",
    "def evaluate_model(model, params, X_train, y_train, X_test, y_test):\n",
    "    grid_search = GridSearchCV(model, params, cv=5, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred_train = best_model.predict(X_train)\n",
    "    y_pred_test = best_model.predict(X_test)\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    return {\n",
    "        \"MSE Train\": mse_train,\n",
    "        \"MSE Test\": mse_test,\n",
    "        \"MAE Test\": mae_test,\n",
    "        \"R2 Score\": r2\n",
    "    }\n",
    "\n",
    "# Evaluación de modelos\n",
    "results = {}\n",
    "for name, mp in models_params.items():\n",
    "    model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                     ('regressor', mp['model'])])\n",
    "    results[name] = evaluate_model(model_pipeline, mp['params'], X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Mostrar resultados\n",
    "for model_name, result in results.items():\n",
    "    print(f\"Modelo: {model_name}\")\n",
    "    for key, value in result.items():\n",
    "        print(f\"{key}: {value}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
