{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DATATHON 2023: NTT-DATA CHALLENGE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Requirements**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /Users/jaumemil/Library/Python/3.11/lib/python/site-packages (from -r requirements.txt (line 1)) (1.25.0)\n",
      "Requirement already satisfied: pandas in /Users/jaumemil/Library/Python/3.11/lib/python/site-packages (from -r requirements.txt (line 2)) (2.1.3)\n",
      "Requirement already satisfied: matplotlib in /Users/jaumemil/Library/Python/3.11/lib/python/site-packages (from -r requirements.txt (line 3)) (3.8.1)\n",
      "Requirement already satisfied: seaborn in /Users/jaumemil/Library/Python/3.11/lib/python/site-packages (from -r requirements.txt (line 4)) (0.13.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/jaumemil/Library/Python/3.11/lib/python/site-packages (from -r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: statsmodels in /Users/jaumemil/Library/Python/3.11/lib/python/site-packages (from -r requirements.txt (line 6)) (0.14.0)\n",
      "Requirement already satisfied: openpyxl in /Users/jaumemil/Library/Python/3.11/lib/python/site-packages (from -r requirements.txt (line 7)) (3.1.2)\n",
      "Requirement already satisfied: pmdarima in /Users/jaumemil/Library/Python/3.11/lib/python/site-packages (from -r requirements.txt (line 8)) (2.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jaumemil/Library/Python/3.11/lib/python/site-packages (from pandas->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jaumemil/Library/Python/3.11/lib/python/site-packages (from pandas->-r requirements.txt (line 2)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/jaumemil/Library/Python/3.11/lib/python/site-packages (from pandas->-r requirements.txt (line 2)) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/jaumemil/Library/Python/3.11/lib/python/site-packages (from matplotlib->-r requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/jaumemil/Library/Python/3.11/lib/python/site-packages (from matplotlib->-r requirements.txt (line 3)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/jaumemil/Library/Python/3.11/lib/python/site-packages (from matplotlib->-r requirements.txt (line 3)) (4.44.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/jaumemil/Library/Python/3.11/lib/python/site-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jaumemil/Library/Python/3.11/lib/python/site-packages (from matplotlib->-r requirements.txt (line 3)) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/jaumemil/Library/Python/3.11/lib/python/site-packages (from matplotlib->-r requirements.txt (line 3)) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/jaumemil/Library/Python/3.11/lib/python/site-packages (from matplotlib->-r requirements.txt (line 3)) (3.1.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/jaumemil/Library/Python/3.11/lib/python/site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/jaumemil/Library/Python/3.11/lib/python/site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/jaumemil/Library/Python/3.11/lib/python/site-packages (from scikit-learn->-r requirements.txt (line 5)) (3.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /Users/jaumemil/Library/Python/3.11/lib/python/site-packages (from statsmodels->-r requirements.txt (line 6)) (0.5.3)\n",
      "Requirement already satisfied: et-xmlfile in /Users/jaumemil/Library/Python/3.11/lib/python/site-packages (from openpyxl->-r requirements.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /Users/jaumemil/Library/Python/3.11/lib/python/site-packages (from pmdarima->-r requirements.txt (line 8)) (3.0.5)\n",
      "Requirement already satisfied: urllib3 in /Users/jaumemil/Library/Python/3.11/lib/python/site-packages (from pmdarima->-r requirements.txt (line 8)) (2.0.7)\n",
      "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /opt/local/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pmdarima->-r requirements.txt (line 8)) (67.6.1)\n",
      "Requirement already satisfied: six in /Users/jaumemil/Library/Python/3.11/lib/python/site-packages (from patsy>=0.5.2->statsmodels->-r requirements.txt (line 6)) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Main Program**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../assets/consumo_material_clean.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values\n",
    "df = df.dropna()\n",
    "\n",
    "# Split \"ORIGEN\" into \"REGION\", \"HOSPITAL\" and \"DEPARTAMENTO\"\n",
    "df['ORIGEN'] = df['ORIGEN'].str.replace('--', '-')\n",
    "df[['REGION', 'HOSPITAL', 'DEPARTAMENTO']] = df['ORIGEN'].str.split('-', expand=True)\n",
    "df = df.drop([\"ORIGEN\"], axis=1)\n",
    "\n",
    "# Categorical variables\n",
    "categorical = ['CODIGO', 'PRODUCTO', 'NUMERO', 'REFERENCIA', 'TIPOCOMPRA', 'REGION', 'HOSPITAL', 'DEPARTAMENTO', 'TGL']\n",
    "df[categorical] = df[categorical].astype('category')\n",
    "\n",
    "# Numeric variables\n",
    "numerical_int = ['CANTIDADCOMPRA', 'UNIDADESCONSUMOCONTENIDAS']\n",
    "numerical_float = ['PRECIO', 'IMPORTELINEA']\n",
    "df[numerical_float] = df[numerical_float].astype('float')\n",
    "\n",
    "# Date format\n",
    "df['FECHAPEDIDO'] = pd.to_datetime(df['FECHAPEDIDO'], format='%d/%m/%y')\n",
    "df['MES'] = df['FECHAPEDIDO'].dt.month\n",
    "df['AÑO'] = df['FECHAPEDIDO'].dt.year\n",
    "df = df.drop('FECHAPEDIDO', axis=1)\n",
    "\n",
    "# Create new variable\n",
    "df['PRECIOUNIDAD'] = df['IMPORTELINEA'] / df['CANTIDADCOMPRA']\n",
    "\n",
    "df.to_csv('../assets/preprocessed_df.csv', index=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "años = df['AÑO'].unique()\n",
    "meses = df['MES'].unique()\n",
    "productos = df['PRODUCTO'].unique()\n",
    "\n",
    "# Crear todas las combinaciones posibles de año, mes y producto\n",
    "todas_las_combinaciones = pd.DataFrame(list(itertools.product(años, meses, productos)), columns=['AÑO', 'MES', 'PRODUCTO'])\n",
    "\n",
    "# Agrupar por año, mes y producto y realizar las operaciones de agregación\n",
    "df_agrupado = df.groupby(['AÑO', 'MES', 'PRODUCTO']).agg({'CANTIDADCOMPRA': 'sum'}).reset_index()\n",
    "\n",
    "# Combinar el DataFrame de todas las combinaciones con el DataFrame agrupado\n",
    "# Usar un merge para asegurarse de que todas las combinaciones estén presentes\n",
    "resultado_final = pd.merge(todas_las_combinaciones, df_agrupado, on=['AÑO', 'MES', 'PRODUCTO'], how='left')\n",
    "\n",
    "# Rellenar los valores faltantes con 0 (o cualquier otro valor que sea apropiado)\n",
    "resultado_final['CANTIDADCOMPRA'] = resultado_final['CANTIDADCOMPRA'].fillna(0)\n",
    "\n",
    "resultado_final.to_csv('../assets/baiges_combinations.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New dataset with groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[['PRODUCTO', 'AÑO', 'MES', 'TIPOCOMPRA', 'HOSPITAL', 'TGL', 'CANTIDADCOMPRA']].copy()\n",
    "\n",
    "años = new_df['AÑO'].unique()\n",
    "meses = new_df['MES'].unique()\n",
    "productos = df['PRODUCTO'].unique()\n",
    "tiposcompra = df['TIPOCOMPRA'].unique()\n",
    "hospital = df['HOSPITAL'].unique()\n",
    "tgl = df['TGL'].unique()\n",
    "\n",
    "todas_las_combinaciones = pd.DataFrame(list(itertools.product(años, meses, productos,tiposcompra,hospital,tgl)), columns=['AÑO', 'MES', 'PRODUCTO','TIPOCOMPRA','HOSPITAL','TGL'])\n",
    "df_agrupado = df.groupby(['AÑO', 'MES', 'PRODUCTO','TIPOCOMPRA','HOSPITAL','TGL']).agg({'CANTIDADCOMPRA': 'sum'}).reset_index()\n",
    "resultado_final.to_csv('../assets/all_combinations.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "new_df = new_df.groupby(['AÑO', 'MES', 'PRODUCTO', 'HOSPITAL', 'TIPOCOMPRA', 'TGL'], observed=True).agg({'CANTIDADCOMPRA': 'sum', 'UNIDADESCONSUMOCONTENIDAS': 'mean', 'PRECIO': 'mean', 'IMPORTELINEA': 'sum', 'PRECIOUNIDAD': 'mean'}).reset_index()\n",
    "\n",
    "new_df.drop(['UNIDADESCONSUMOCONTENIDAS', 'PRECIO', 'IMPORTELINEA', 'PRECIOUNIDAD'], axis=1, inplace=True)\n",
    "\n",
    "new_df.to_csv('../assets/new_df.csv', index=False)\n",
    "\n",
    "new_df.head()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_year = 2023\n",
    "train = new_df.loc[new_df['AÑO'] < split_year]\n",
    "test = new_df.loc[new_df['AÑO'] >= split_year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('../assets/train.csv', index=False)\n",
    "test.to_csv('../assets/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima\n",
    "from pmdarima.arima.utils import ndiffs\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "# Carga de datos\n",
    "data = pd.read_csv('new_df.csv')\n",
    "\n",
    "# Agrupación de datos por producto y mes\n",
    "grouped_data = data.groupby(['PRODUCTO', 'AÑO', 'MES']).agg({'CANTIDADCOMPRA': 'sum'}).reset_index()\n",
    "\n",
    "# Inicializar un diccionario para almacenar los modelos\n",
    "models = {}\n",
    "\n",
    "# Función para verificar la estacionariedad\n",
    "def check_stationarity(ts):\n",
    "    return ndiffs(ts, test='adf') > 0\n",
    "\n",
    "# Iterar sobre cada producto\n",
    "for product_name in grouped_data['PRODUCTO'].unique():\n",
    "    # Filtrar para un producto específico\n",
    "    product_data = grouped_data[grouped_data['PRODUCTO'] == product_name]\n",
    "\n",
    "    # Convertir a serie temporal\n",
    "    product_series = product_data.pivot_table(values='CANTIDADCOMPRA', index=['AÑO', 'MES'], aggfunc='sum')\n",
    "\n",
    "    # Dividir en conjunto de entrenamiento y prueba\n",
    "    train = product_series[product_series.index.get_level_values('AÑO') < 2023]\n",
    "    test = product_series[(product_series.index.get_level_values('AÑO') == 2023) & \n",
    "                          (product_series.index.get_level_values('MES') <= 10)]\n",
    "\n",
    "    # Verificar si hay suficientes datos para el modelado\n",
    "    if len(train) < 24 or not check_stationarity(train):\n",
    "        print(f\"No hay suficientes datos o la serie no es estacionaria para el producto {product_name}.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Aplicar Auto ARIMA\n",
    "        model = auto_arima(train, seasonal=True, m=12, trace=True, error_action='ignore', suppress_warnings=True)\n",
    "        \n",
    "        # Almacenar el modelo\n",
    "        models[product_name] = model\n",
    "    except Exception as e:\n",
    "        print(f\"Error al modelar el producto {product_name}: {e}\")\n",
    "\n",
    "# Preparar los datos de prueba\n",
    "test_data = grouped_data[grouped_data['AÑO'] == 2023]\n",
    "test_data = test_data[test_data['MES'] <= 10]\n",
    "test_data = test_data.pivot_table(values='CANTIDADCOMPRA', index='PRODUCTO', columns='MES', aggfunc='sum')\n",
    "\n",
    "# Realizar predicciones y comparar con los datos de prueba\n",
    "all_predictions = []\n",
    "all_actuals = []\n",
    "for product_name, model in models.items():\n",
    "    if product_name in test_data.index:\n",
    "        # Número de meses a predecir\n",
    "        months_to_predict = len(test_data.columns)\n",
    "        \n",
    "        # Realizar la predicción\n",
    "        forecast = model.predict(n_periods=months_to_predict)\n",
    "        all_predictions.extend(forecast)\n",
    "        \n",
    "        # Obtener los valores reales\n",
    "        actual_values = test_data.loc[product_name].values\n",
    "        all_actuals.extend(actual_values)\n",
    "\n",
    "        # Gráfico de las predicciones para cada producto\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(actual_values, label='Valores Reales', color='blue')\n",
    "        plt.plot(forecast, label='Predicciones', color='red', linestyle='--')\n",
    "        plt.title(f'Comparación de Valores Reales y Predicciones para {product_name}')\n",
    "        plt.xlabel('Meses')\n",
    "        plt.ylabel('Cantidad Comprada')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "# Cálculo de métricas de error globales\n",
    "mse = mean_squared_error(all_actuals, all_predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(all_actuals, all_predictions)\n",
    "\n",
    "print(f\"MSE Global: {mse}, RMSE Global: {rmse}, MAE Global: {mae}\")\n",
    "\n",
    "# Análisis de los residuos\n",
    "residuos = np.array(all_actuals) - np.array(all_predictions)\n",
    "dw_stat = durbin_watson(residuos)\n",
    "print(f\"Estadístico de Durbin-Watson: {dw_stat}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
