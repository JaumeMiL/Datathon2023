{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DATATHON 2023: NTT-DATA CHALLENGE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Requirements**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 1)) (1.26.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 2)) (2.1.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 3)) (3.8.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 4)) (0.12.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: statsmodels in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 6)) (0.14.0)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 7)) (3.1.2)\n",
      "Requirement already satisfied: pmdarima in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 8)) (2.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (3.1.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.11.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (3.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from statsmodels->-r requirements.txt (line 6)) (0.5.3)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openpyxl->-r requirements.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pmdarima->-r requirements.txt (line 8)) (3.0.5)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pmdarima->-r requirements.txt (line 8)) (1.26.15)\n",
      "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pmdarima->-r requirements.txt (line 8)) (65.5.0)\n",
      "Requirement already satisfied: six in c:\\users\\cai selvas sala\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from patsy>=0.5.2->statsmodels->-r requirements.txt (line 6)) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Main Program**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../assets/consumo_material_clean.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values\n",
    "df = df.dropna()\n",
    "\n",
    "# Split \"ORIGEN\" into \"REGION\", \"HOSPITAL\" and \"DEPARTAMENTO\"\n",
    "df['ORIGEN'] = df['ORIGEN'].str.replace('--', '-')\n",
    "df[['REGION', 'HOSPITAL', 'DEPARTAMENTO']] = df['ORIGEN'].str.split('-', expand=True)\n",
    "df = df.drop([\"ORIGEN\"], axis=1)\n",
    "\n",
    "# Categorical variables\n",
    "categorical = ['CODIGO', 'PRODUCTO', 'NUMERO', 'REFERENCIA', 'TIPOCOMPRA', 'REGION', 'HOSPITAL', 'DEPARTAMENTO', 'TGL']\n",
    "df[categorical] = df[categorical].astype('category')\n",
    "\n",
    "# Numeric variables\n",
    "numerical_int = ['CANTIDADCOMPRA', 'UNIDADESCONSUMOCONTENIDAS']\n",
    "numerical_float = ['PRECIO', 'IMPORTELINEA']\n",
    "df[numerical_float] = df[numerical_float].astype('float')\n",
    "\n",
    "# Date format\n",
    "df['FECHAPEDIDO'] = pd.to_datetime(df['FECHAPEDIDO'], format='%d/%m/%y')\n",
    "df['MES'] = df['FECHAPEDIDO'].dt.month\n",
    "df['AÑO'] = df['FECHAPEDIDO'].dt.year\n",
    "df = df.drop('FECHAPEDIDO', axis=1)\n",
    "\n",
    "# Create new variable\n",
    "df['PRECIOUNIDAD'] = df['IMPORTELINEA'] / df['CANTIDADCOMPRA']\n",
    "\n",
    "df.to_csv('../assets/preprocessed_df.csv', index=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "años = df['AÑO'].unique()\n",
    "meses = df['MES'].unique()\n",
    "productos = df['PRODUCTO'].unique()\n",
    "\n",
    "# Crear todas las combinaciones posibles de año, mes y producto\n",
    "todas_las_combinaciones = pd.DataFrame(list(itertools.product(años, meses, productos)), columns=['AÑO', 'MES', 'PRODUCTO'])\n",
    "\n",
    "# Agrupar por año, mes y producto y realizar las operaciones de agregación\n",
    "df_agrupado = df.groupby(['AÑO', 'MES', 'PRODUCTO']).agg({'CANTIDADCOMPRA': 'sum'}).reset_index()\n",
    "\n",
    "# Combinar el DataFrame de todas las combinaciones con el DataFrame agrupado\n",
    "# Usar un merge para asegurarse de que todas las combinaciones estén presentes\n",
    "resultado_final = pd.merge(todas_las_combinaciones, df_agrupado, on=['AÑO', 'MES', 'PRODUCTO'], how='left')\n",
    "\n",
    "# Rellenar los valores faltantes con 0 (o cualquier otro valor que sea apropiado)\n",
    "resultado_final['CANTIDADCOMPRA'] = resultado_final['CANTIDADCOMPRA'].fillna(0)\n",
    "\n",
    "resultado_final.to_csv('../assets/cantidadcompra_combinations.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "años = df['AÑO'].unique()\n",
    "meses = df['MES'].unique()\n",
    "productos = df['PRODUCTO'].unique()\n",
    "\n",
    "# Crear todas las combinaciones posibles de año, mes y producto\n",
    "todas_las_combinaciones = pd.DataFrame(list(itertools.product(años, meses, productos)), columns=['AÑO', 'MES', 'PRODUCTO'])\n",
    "\n",
    "# Agrupar por año, mes y producto y realizar las operaciones de agregación\n",
    "df_agrupado = df.groupby(['AÑO', 'MES', 'PRODUCTO']).agg({'PRECIOUNIDAD': 'mean'}).reset_index()\n",
    "\n",
    "# Combinar el DataFrame de todas las combinaciones con el DataFrame agrupado\n",
    "# Usar un merge para asegurarse de que todas las combinaciones estén presentes\n",
    "resultado_final = pd.merge(todas_las_combinaciones, df_agrupado, on=['AÑO', 'MES', 'PRODUCTO'], how='left')\n",
    "\n",
    "# Rellenar los valores faltantes con 0 (o cualquier otro valor que sea apropiado)\n",
    "resultado_final['PRECIOUNIDAD'] = resultado_final['PRECIOUNIDAD'].fillna(0)\n",
    "\n",
    "resultado_final.to_csv('../assets/preciounidad_combinations.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_year = 2023\n",
    "train = new_df.loc[new_df['AÑO'] < split_year]\n",
    "test = new_df.loc[new_df['AÑO'] >= split_year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('../assets/train.csv', index=False)\n",
    "test.to_csv('../assets/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARIMA TO PREDICT CANTIDADCOMPRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima\n",
    "from pmdarima.arima.utils import ndiffs\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Carga de datos\n",
    "data = pd.read_csv('../assets/cantidadcompra_combinations.csv')\n",
    "\n",
    "# Agrupación de datos por producto y mes\n",
    "grouped_data = data.groupby(['PRODUCTO', 'AÑO', 'MES']).agg({'CANTIDADCOMPRA': 'sum'}).reset_index()\n",
    "\n",
    "# Inicializar un diccionario para almacenar los modelos\n",
    "models = {}\n",
    "\n",
    "# Función para verificar la estacionariedad\n",
    "def check_stationarity(ts):\n",
    "    return ndiffs(ts, test='adf') > 0\n",
    "\n",
    "# Iterar sobre cada producto\n",
    "for product_name in grouped_data['PRODUCTO'].unique():\n",
    "    product_data = grouped_data[grouped_data['PRODUCTO'] == product_name].copy()\n",
    "\n",
    "    # Crear un índice de tiempo combinando año y mes\n",
    "    product_data.loc[:, 'Fecha'] = pd.to_datetime(product_data['AÑO'].astype(str) + '-' + product_data['MES'].astype(str)) + MonthEnd(1)\n",
    "    product_series = product_data.set_index('Fecha')['CANTIDADCOMPRA']\n",
    "\n",
    "    # Dividir en conjunto de entrenamiento y prueba\n",
    "    train = product_series[:'2022-12-31']\n",
    "    test = product_series['2023-01-31':'2023-10-31']\n",
    "\n",
    "    try:\n",
    "        # Aplicar Auto ARIMA\n",
    "        stationarity = check_stationarity(train)\n",
    "        model = auto_arima(train, seasonal=stationarity, m=12 if stationarity else 0, trace=True, error_action='ignore', suppress_warnings=True)\n",
    "        models[product_name] = model\n",
    "    except Exception as e:\n",
    "        print(f\"Error al modelar el producto {product_name}: {e}\")\n",
    "\n",
    "# Preparar los datos de prueba y alinearlos con las predicciones\n",
    "test_data = data[(data['AÑO'] == 2023) & (data['MES'] <= 10)].copy()\n",
    "\n",
    "# Realizar predicciones y comparar con los datos de prueba\n",
    "for product_name, model in models.items():\n",
    "    if product_name in grouped_data['PRODUCTO'].unique():\n",
    "        # Realizar la predicción\n",
    "        forecast = model.predict(n_periods=10)\n",
    "\n",
    "        # Insertar predicciones en test_data\n",
    "        for i, month in enumerate(range(1, 11)):\n",
    "            test_data.loc[(test_data['PRODUCTO'] == product_name) & (test_data['MES'] == month), 'predicted'] = forecast[i]\n",
    "\n",
    "        # Extraer valores reales para el gráfico\n",
    "        actual_values = test_data[(test_data['PRODUCTO'] == product_name) & (test_data['AÑO'] == 2023) & (test_data['MES'] <= 10)]['CANTIDADCOMPRA']\n",
    "\n",
    "        # Gráfico de las predicciones para cada producto\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(1, 11), actual_values, label='Valores Reales', color='blue')\n",
    "        plt.plot(range(1, 11), forecast, label='Predicciones', color='red', linestyle='--')\n",
    "        plt.title(f'Comparación de Valores Reales y Predicciones para {product_name} en 2023')\n",
    "        plt.xlabel('Meses del 2023')\n",
    "        plt.ylabel('Cantidad Comprada')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Preparar listas para almacenar todos los valores reales y predichos\n",
    "all_actual_values = []\n",
    "all_predicted_values = []\n",
    "\n",
    "for product_name in grouped_data['PRODUCTO'].unique():\n",
    "    if product_name in test_data['PRODUCTO'].unique():\n",
    "        actual_values = test_data[(test_data['PRODUCTO'] == product_name) & (test_data['AÑO'] == 2023) & (test_data['MES'] <= 10)]['CANTIDADCOMPRA']\n",
    "        predicted_values = test_data[(test_data['PRODUCTO'] == product_name) & (test_data['AÑO'] == 2023) & (test_data['MES'] <= 10)]['predicted']\n",
    "\n",
    "        # Añadir valores reales y predichos a las listas generales\n",
    "        all_actual_values.extend(actual_values)\n",
    "        all_predicted_values.extend(predicted_values)\n",
    "\n",
    "# Calcular R^2 para todos los productos en conjunto\n",
    "r2_general = r2_score(all_actual_values, all_predicted_values)\n",
    "print(f\"R^2 general: {r2_general}\")\n",
    "\n",
    "\n",
    "# Guardar el conjunto de datos de prueba con las predicciones en un archivo CSV\n",
    "test_data.to_csv('../assets/cantidadcompra_predicted.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARIMA TO PREDICT PRECIOUNIDAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima\n",
    "from pmdarima.arima.utils import ndiffs\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Carga de datos\n",
    "data = pd.read_csv('../assets/preciounidad_combinations.csv')\n",
    "\n",
    "# Agrupación de datos por producto y mes\n",
    "grouped_data = data.groupby(['PRODUCTO', 'AÑO', 'MES']).agg({'PRECIOUNIDAD': 'mean'}).reset_index()\n",
    "\n",
    "# Inicializar un diccionario para almacenar los modelos\n",
    "models = {}\n",
    "\n",
    "# Función para verificar la estacionariedad\n",
    "def check_stationarity(ts):\n",
    "    return ndiffs(ts, test='adf') > 0\n",
    "\n",
    "# Iterar sobre cada producto\n",
    "for product_name in grouped_data['PRODUCTO'].unique():\n",
    "    product_data = grouped_data[grouped_data['PRODUCTO'] == product_name].copy()\n",
    "\n",
    "    # Crear un índice de tiempo combinando año y mes\n",
    "    product_data.loc[:, 'Fecha'] = pd.to_datetime(product_data['AÑO'].astype(str) + '-' + product_data['MES'].astype(str)) + MonthEnd(1)\n",
    "    product_series = product_data.set_index('Fecha')['PRECIOUNIDAD']\n",
    "\n",
    "    # Dividir en conjunto de entrenamiento y prueba\n",
    "    train = product_series[:'2022-12-31']\n",
    "    test = product_series['2023-01-31':'2023-10-31']\n",
    "\n",
    "    try:\n",
    "        # Aplicar Auto ARIMA\n",
    "        stationarity = check_stationarity(train)\n",
    "        model = auto_arima(train, seasonal=stationarity, m=12 if stationarity else 0, trace=True, error_action='ignore', suppress_warnings=True)\n",
    "        models[product_name] = model\n",
    "    except Exception as e:\n",
    "        print(f\"Error al modelar el producto {product_name}: {e}\")\n",
    "\n",
    "# Preparar los datos de prueba y alinearlos con las predicciones\n",
    "test_data = data[(data['AÑO'] == 2023) & (data['MES'] <= 10)].copy()\n",
    "\n",
    "# Realizar predicciones y comparar con los datos de prueba\n",
    "for product_name, model in models.items():\n",
    "    if product_name in grouped_data['PRODUCTO'].unique():\n",
    "        # Realizar la predicción\n",
    "        forecast = model.predict(n_periods=10)\n",
    "\n",
    "        # Insertar predicciones en test_data\n",
    "        for i, month in enumerate(range(1, 11)):\n",
    "            test_data.loc[(test_data['PRODUCTO'] == product_name) & (test_data['MES'] == month), 'predicted'] = forecast[i]\n",
    "\n",
    "        # Extraer valores reales para el gráfico\n",
    "        actual_values = test_data[(test_data['PRODUCTO'] == product_name) & (test_data['AÑO'] == 2023) & (test_data['MES'] <= 10)]['PRECIOUNIDAD']\n",
    "\n",
    "        # Gráfico de las predicciones para cada producto\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(1, 11), actual_values, label='Valores Reales', color='blue')\n",
    "        plt.plot(range(1, 11), forecast, label='Predicciones', color='red', linestyle='--')\n",
    "        plt.title(f'Comparación de Valores Reales y Predicciones para {product_name} en 2023')\n",
    "        plt.xlabel('Meses del 2023')\n",
    "        plt.ylabel('Cantidad Comprada')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Preparar listas para almacenar todos los valores reales y predichos\n",
    "all_actual_values = []\n",
    "all_predicted_values = []\n",
    "\n",
    "for product_name in grouped_data['PRODUCTO'].unique():\n",
    "    if product_name in test_data['PRODUCTO'].unique():\n",
    "        actual_values = test_data[(test_data['PRODUCTO'] == product_name) & (test_data['AÑO'] == 2023) & (test_data['MES'] <= 10)]['PRECIOUNIDAD']\n",
    "        predicted_values = test_data[(test_data['PRODUCTO'] == product_name) & (test_data['AÑO'] == 2023) & (test_data['MES'] <= 10)]['predicted']\n",
    "\n",
    "        # Añadir valores reales y predichos a las listas generales\n",
    "        all_actual_values.extend(actual_values)\n",
    "        all_predicted_values.extend(predicted_values)\n",
    "\n",
    "# Calcular R^2 para todos los productos en conjunto\n",
    "r2_general = r2_score(all_actual_values, all_predicted_values)\n",
    "print(f\"R^2 general: {r2_general}\")\n",
    "\n",
    "\n",
    "# Guardar el conjunto de datos de prueba con las predicciones en un archivo CSV\n",
    "test_data.to_csv('../assets/preciounidad_predicted.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge results to a final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_partial_2023 = pd.read_csv('../assets/test.csv')\n",
    "predicted_partial_2023 = predicted_partial_2023[['AÑO', 'MES', 'PRODUCTO']]\n",
    "\n",
    "predicted_cantidadcompra = pd.read_csv('../assets/cantidadcompra_predicted.csv')\n",
    "predicted_partial_2023['PREDICTED_CANTIDADCOMPRA'] = predicted_cantidadcompra['predicted']\n",
    "\n",
    "predicted_preciounidad = pd.read_csv('../assets/preciounidad_predicted.csv')\n",
    "predicted_partial_2023['PREDICTED_PRECIOUNIDAD'] = predicted_preciounidad['predicted']\n",
    "\n",
    "predicted_partial_2023['PREDICTED_IMPORTELINEA'] = predicted_partial_2023['PREDICTED_CANTIDADCOMPRA'] * predicted_partial_2023['PREDICTED_PRECIOUNIDAD']\n",
    "\n",
    "predicted_partial_2023.to_csv('../assets/predicted_partial_2023.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
