{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DATATHON 2023: NTT-DATA CHALLENGE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Requirements**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Main Program**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../assets/consumo_material_clean.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values\n",
    "df = df.dropna()\n",
    "\n",
    "# Split \"ORIGEN\" into \"REGION\", \"HOSPITAL\" and \"DEPARTAMENTO\"\n",
    "df['ORIGEN'] = df['ORIGEN'].str.replace('--', '-')\n",
    "df[['REGION', 'HOSPITAL', 'DEPARTAMENTO']] = df['ORIGEN'].str.split('-', expand=True)\n",
    "df = df.drop([\"ORIGEN\"], axis=1)\n",
    "\n",
    "# Categorical variables\n",
    "categorical = ['CODIGO', 'PRODUCTO', 'NUMERO', 'REFERENCIA', 'TIPOCOMPRA', 'REGION', 'HOSPITAL', 'DEPARTAMENTO', 'TGL']\n",
    "df[categorical] = df[categorical].astype('category')\n",
    "\n",
    "# Numeric variables\n",
    "numerical_int = ['CANTIDADCOMPRA', 'UNIDADESCONSUMOCONTENIDAS']\n",
    "numerical_float = ['PRECIO', 'IMPORTELINEA']\n",
    "df[numerical_float] = df[numerical_float].astype('float')\n",
    "\n",
    "# Date format\n",
    "df['FECHAPEDIDO'] = pd.to_datetime(df['FECHAPEDIDO'], format='%d/%m/%y')\n",
    "df['MES'] = df['FECHAPEDIDO'].dt.month\n",
    "df['AÑO'] = df['FECHAPEDIDO'].dt.year\n",
    "df = df.drop('FECHAPEDIDO', axis=1)\n",
    "\n",
    "# Create new variable\n",
    "df['PRECIOUNIDAD'] = df['IMPORTELINEA'] / df['CANTIDADCOMPRA']\n",
    "\n",
    "df.to_csv('../assets/preprocessed_df.csv', index=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "años = df['AÑO'].unique()\n",
    "meses = df['MES'].unique()\n",
    "productos = df['PRODUCTO'].unique()\n",
    "\n",
    "# Crear todas las combinaciones posibles de año, mes y producto\n",
    "todas_las_combinaciones = pd.DataFrame(list(itertools.product(años, meses, productos)), columns=['AÑO', 'MES', 'PRODUCTO'])\n",
    "\n",
    "# Agrupar por año, mes y producto y realizar las operaciones de agregación\n",
    "df_agrupado = df.groupby(['AÑO', 'MES', 'PRODUCTO']).agg({'CANTIDADCOMPRA': 'sum'}).reset_index()\n",
    "\n",
    "# Combinar el DataFrame de todas las combinaciones con el DataFrame agrupado\n",
    "# Usar un merge para asegurarse de que todas las combinaciones estén presentes\n",
    "resultado_final = pd.merge(todas_las_combinaciones, df_agrupado, on=['AÑO', 'MES', 'PRODUCTO'], how='left')\n",
    "\n",
    "# Rellenar los valores faltantes con 0 (o cualquier otro valor que sea apropiado)\n",
    "resultado_final['CANTIDADCOMPRA'] = resultado_final['CANTIDADCOMPRA'].fillna(0)\n",
    "\n",
    "resultado_final.to_csv('../assets/cantidadcompra_combinations.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "años = df['AÑO'].unique()\n",
    "meses = df['MES'].unique()\n",
    "productos = df['PRODUCTO'].unique()\n",
    "\n",
    "# Crear todas las combinaciones posibles de año, mes y producto\n",
    "todas_las_combinaciones = pd.DataFrame(list(itertools.product(años, meses, productos)), columns=['AÑO', 'MES', 'PRODUCTO'])\n",
    "\n",
    "# Agrupar por año, mes y producto y realizar las operaciones de agregación\n",
    "df_agrupado = df.groupby(['AÑO', 'MES', 'PRODUCTO']).agg({'PRECIOUNIDAD': 'mean'}).reset_index()\n",
    "\n",
    "# Combinar el DataFrame de todas las combinaciones con el DataFrame agrupado\n",
    "# Usar un merge para asegurarse de que todas las combinaciones estén presentes\n",
    "resultado_final = pd.merge(todas_las_combinaciones, df_agrupado, on=['AÑO', 'MES', 'PRODUCTO'], how='left')\n",
    "\n",
    "# Rellenar los valores faltantes con 0 (o cualquier otro valor que sea apropiado)\n",
    "resultado_final['PRECIOUNIDAD'] = resultado_final['PRECIOUNIDAD'].fillna(0)\n",
    "\n",
    "resultado_final.to_csv('../assets/preciounidad_combinations.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARIMA TO PREDICT CANTIDADCOMPRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima\n",
    "from pmdarima.arima.utils import ndiffs\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "\n",
    "# Carga de datos\n",
    "data = pd.read_csv('../assets/cantidadcompra_combinations.csv')\n",
    "\n",
    "# Agrupación de datos por producto y mes\n",
    "grouped_data = data.groupby(['AÑO', 'MES', 'PRODUCTO']).agg({'CANTIDADCOMPRA': 'sum'}).reset_index()\n",
    "\n",
    "# Inicializar un diccionario para almacenar los modelos\n",
    "models = {}\n",
    "\n",
    "# Función para verificar la estacionariedad\n",
    "def check_stationarity(ts):\n",
    "    return ndiffs(ts, test='adf') > 0\n",
    "\n",
    "# Iterar sobre cada producto\n",
    "for product_name in grouped_data['PRODUCTO'].unique():\n",
    "    product_data = grouped_data[grouped_data['PRODUCTO'] == product_name].copy()\n",
    "\n",
    "    # Crear un índice de tiempo combinando año y mes\n",
    "    product_data.loc[:, 'Fecha'] = pd.to_datetime(product_data['AÑO'].astype(str) + '-' + product_data['MES'].astype(str)) + MonthEnd(1)\n",
    "    product_series = product_data.set_index('Fecha')['CANTIDADCOMPRA']\n",
    "\n",
    "    # Dividir en conjunto de entrenamiento y prueba\n",
    "    train = product_series[:'2022-12-31']\n",
    "    test = product_series['2023-01-31':'2023-10-31']\n",
    "\n",
    "    try:\n",
    "        # Aplicar Auto ARIMA\n",
    "        stationarity = check_stationarity(train)\n",
    "        model = auto_arima(train, seasonal=stationarity, m=12 if stationarity else 0, trace=True, error_action='ignore', suppress_warnings=True)\n",
    "        models[product_name] = model\n",
    "    except Exception as e:\n",
    "        print(f\"Error al modelar el producto {product_name}: {e}\")\n",
    "\n",
    "# Preparar los datos de prueba y alinearlos con las predicciones\n",
    "test_data = data[(data['AÑO'] == 2023) & (data['MES'] <= 10)].copy()\n",
    "\n",
    "# Realizar predicciones y comparar con los datos de prueba\n",
    "for product_name, model in models.items():\n",
    "    if product_name in grouped_data['PRODUCTO'].unique():\n",
    "        # Realizar la predicción\n",
    "        forecast = model.predict(n_periods=10)\n",
    "\n",
    "        # Insertar predicciones en test_data\n",
    "        for i, month in enumerate(range(1, 11)):\n",
    "            test_data.loc[(test_data['PRODUCTO'] == product_name) & (test_data['MES'] == month), 'predicted'] = forecast[i]\n",
    "\n",
    "        # Extraer valores reales para el gráfico\n",
    "        actual_values = test_data[(test_data['PRODUCTO'] == product_name) & (test_data['AÑO'] == 2023) & (test_data['MES'] <= 10)]['CANTIDADCOMPRA']\n",
    "\n",
    "        # Gráfico de las predicciones para cada producto\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(1, 11), actual_values, label='Valores Reales', color='blue')\n",
    "        plt.plot(range(1, 11), forecast, label='Predicciones', color='red', linestyle='--')\n",
    "        plt.title(f'Comparación de Valores Reales y Predicciones para {product_name} en 2023')\n",
    "        plt.xlabel('Meses del 2023')\n",
    "        plt.ylabel('Cantidad Comprada')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Preparar listas para almacenar todos los valores reales y predichos\n",
    "all_actual_values = []\n",
    "all_predicted_values = []\n",
    "\n",
    "for product_name in grouped_data['PRODUCTO'].unique():\n",
    "    if product_name in test_data['PRODUCTO'].unique():\n",
    "        actual_values = test_data[(test_data['PRODUCTO'] == product_name) & (test_data['AÑO'] == 2023) & (test_data['MES'] <= 10)]['CANTIDADCOMPRA']\n",
    "        predicted_values = test_data[(test_data['PRODUCTO'] == product_name) & (test_data['AÑO'] == 2023) & (test_data['MES'] <= 10)]['predicted']\n",
    "\n",
    "        # Añadir valores reales y predichos a las listas generales\n",
    "        all_actual_values.extend(actual_values)\n",
    "        all_predicted_values.extend(predicted_values)\n",
    "\n",
    "# Calcular R^2 para todos los productos en conjunto\n",
    "r2_general = r2_score(all_actual_values, all_predicted_values)\n",
    "print(f\"R^2 general: {r2_general}\")\n",
    "\n",
    "\n",
    "# Guardar el conjunto de datos de prueba con las predicciones en un archivo CSV\n",
    "test_data.to_csv('../assets/cantidadcompra_predicted.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARIMA TO PREDICT PRECIOUNIDAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima\n",
    "from pmdarima.arima.utils import ndiffs\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "\n",
    "# Carga de datos\n",
    "data = pd.read_csv('../assets/preciounidad_combinations.csv')\n",
    "\n",
    "# Agrupación de datos por producto y mes\n",
    "grouped_data = data.groupby(['AÑO', 'MES', 'PRODUCTO']).agg({'PRECIOUNIDAD': 'mean'}).reset_index()\n",
    "\n",
    "# Inicializar un diccionario para almacenar los modelos\n",
    "models = {}\n",
    "\n",
    "# Función para verificar la estacionariedad\n",
    "def check_stationarity(ts):\n",
    "    return ndiffs(ts, test='adf') > 0\n",
    "\n",
    "# Iterar sobre cada producto\n",
    "for product_name in grouped_data['PRODUCTO'].unique():\n",
    "    product_data = grouped_data[grouped_data['PRODUCTO'] == product_name].copy()\n",
    "\n",
    "    # Crear un índice de tiempo combinando año y mes\n",
    "    product_data.loc[:, 'Fecha'] = pd.to_datetime(product_data['AÑO'].astype(str) + '-' + product_data['MES'].astype(str)) + MonthEnd(1)\n",
    "    product_series = product_data.set_index('Fecha')['PRECIOUNIDAD']\n",
    "\n",
    "    # Dividir en conjunto de entrenamiento y prueba\n",
    "    train = product_series[:'2022-12-31']\n",
    "    test = product_series['2023-01-31':'2023-10-31']\n",
    "\n",
    "    try:\n",
    "        # Aplicar Auto ARIMA\n",
    "        stationarity = check_stationarity(train)\n",
    "        model = auto_arima(train, seasonal=stationarity, m=12 if stationarity else 0, trace=True, error_action='ignore', suppress_warnings=True)\n",
    "        models[product_name] = model\n",
    "    except Exception as e:\n",
    "        print(f\"Error al modelar el producto {product_name}: {e}\")\n",
    "\n",
    "# Preparar los datos de prueba y alinearlos con las predicciones\n",
    "test_data = data[(data['AÑO'] == 2023) & (data['MES'] <= 10)].copy()\n",
    "\n",
    "# Realizar predicciones y comparar con los datos de prueba\n",
    "for product_name, model in models.items():\n",
    "    if product_name in grouped_data['PRODUCTO'].unique():\n",
    "        # Realizar la predicción\n",
    "        forecast = model.predict(n_periods=10)\n",
    "\n",
    "        # Insertar predicciones en test_data\n",
    "        for i, month in enumerate(range(1, 11)):\n",
    "            test_data.loc[(test_data['PRODUCTO'] == product_name) & (test_data['MES'] == month), 'predicted'] = forecast[i]\n",
    "\n",
    "        # Extraer valores reales para el gráfico\n",
    "        actual_values = test_data[(test_data['PRODUCTO'] == product_name) & (test_data['AÑO'] == 2023) & (test_data['MES'] <= 10)]['PRECIOUNIDAD']\n",
    "\n",
    "        # Gráfico de las predicciones para cada producto\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(1, 11), actual_values, label='Valores Reales', color='blue')\n",
    "        plt.plot(range(1, 11), forecast, label='Predicciones', color='red', linestyle='--')\n",
    "        plt.title(f'Comparación de Valores Reales y Predicciones para {product_name} en 2023')\n",
    "        plt.xlabel('Meses del 2023')\n",
    "        plt.ylabel('Cantidad Comprada')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Preparar listas para almacenar todos los valores reales y predichos\n",
    "all_actual_values = []\n",
    "all_predicted_values = []\n",
    "\n",
    "for product_name in grouped_data['PRODUCTO'].unique():\n",
    "    if product_name in test_data['PRODUCTO'].unique():\n",
    "        actual_values = test_data[(test_data['PRODUCTO'] == product_name) & (test_data['AÑO'] == 2023) & (test_data['MES'] <= 10)]['PRECIOUNIDAD']\n",
    "        predicted_values = test_data[(test_data['PRODUCTO'] == product_name) & (test_data['AÑO'] == 2023) & (test_data['MES'] <= 10)]['predicted']\n",
    "\n",
    "        # Añadir valores reales y predichos a las listas generales\n",
    "        all_actual_values.extend(actual_values)\n",
    "        all_predicted_values.extend(predicted_values)\n",
    "\n",
    "# Calcular R^2 para todos los productos en conjunto\n",
    "r2_general = r2_score(all_actual_values, all_predicted_values)\n",
    "print(f\"R^2 general: {r2_general}\")\n",
    "\n",
    "\n",
    "# Guardar el conjunto de datos de prueba con las predicciones en un archivo CSV\n",
    "test_data.to_csv('../assets/preciounidad_predicted.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprovamos las correlaciones entre los valores originales y los predecidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the predicted data\n",
    "predicted_data_1 = pd.read_csv('../assets/cantidadcompra_predicted.csv')\n",
    "\n",
    "# Create a scatter plot of predicted vs actual values\n",
    "plt.scatter(predicted_data_1['CANTIDADCOMPRA'], predicted_data_1['predicted'])\n",
    "plt.title('Correlación entre valores reales y predichos de CANTIDADCOMPRA')\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Valores Predichos')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the predicted data\n",
    "predicted_data_2 = pd.read_csv('../assets/preciounidad_predicted.csv')\n",
    "\n",
    "# Create a scatter plot of predicted vs actual values\n",
    "plt.scatter(predicted_data_2['PRECIOUNIDAD'], predicted_data_2['predicted'])\n",
    "plt.title('Correlación entre valores reales y predichos de PRECIOUNIDAD')\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Valores Predichos')\n",
    "\n",
    "# Set limits on the x and y axis to avoid representing outliers\n",
    "plt.xlim(0, 30)\n",
    "plt.ylim(0, 30)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge results to a final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_partial_2023 = pd.read_csv('../assets/cantidadcompra_predicted.csv')\n",
    "predicted_partial_2023 = predicted_partial_2023[['AÑO', 'MES', 'PRODUCTO', 'predicted']]\n",
    "predicted_partial_2023 = predicted_partial_2023.rename(columns={'predicted': 'PREDICTED_CANTIDADCOMPRA'})\n",
    "\n",
    "predicted_preciounidad = pd.read_csv('../assets/preciounidad_predicted.csv')\n",
    "predicted_partial_2023['PREDICTED_PRECIOUNIDAD'] = predicted_preciounidad['predicted']\n",
    "\n",
    "predicted_partial_2023['PREDICTED_IMPORTELINEA'] = predicted_partial_2023['PREDICTED_CANTIDADCOMPRA'] * predicted_partial_2023['PREDICTED_PRECIOUNIDAD']\n",
    "\n",
    "predicted_partial_2023.to_csv('../assets/predicted_partial_2023.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the final model to predict CANTIDADCOMPRA and PRECIOUNIDAD for all 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_2023 = pd.read_csv('../assets/cantidadcompra_predicted.csv')\n",
    "predicted_2023 = predicted_partial_2023[['AÑO', 'MES', 'PRODUCTO']]\n",
    "\n",
    "from pmdarima import auto_arima\n",
    "from pmdarima.arima.utils import ndiffs\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "\n",
    "# WE START BY PREDICTING 'CANTIDADCOMPRA' FOR ALL THE MONTHS OF 2023\n",
    "\n",
    "# Carga de datos\n",
    "data = pd.read_csv('../assets/cantidadcompra_combinations.csv')\n",
    "\n",
    "# Agrupación de datos por producto y mes\n",
    "grouped_data = data.groupby(['AÑO', 'MES', 'PRODUCTO']).agg({'CANTIDADCOMPRA': 'sum'}).reset_index()\n",
    "\n",
    "# Inicializar un diccionario para almacenar los modelos\n",
    "models = {}\n",
    "\n",
    "# Función para verificar la estacionariedad\n",
    "\n",
    "def check_stationarity(ts):\n",
    "    return ndiffs(ts, test='adf') > 0\n",
    "\n",
    "# Iterar sobre cada producto\n",
    "for product_name in grouped_data['PRODUCTO'].unique():\n",
    "    product_data = grouped_data[grouped_data['PRODUCTO'] == product_name].copy()\n",
    "\n",
    "    # Crear un índice de tiempo combinando año y mes\n",
    "    product_data.loc[:, 'Fecha'] = pd.to_datetime(product_data['AÑO'].astype(str) + '-' + product_data['MES'].astype(str)) + MonthEnd(1)\n",
    "    product_series = product_data.set_index('Fecha')['CANTIDADCOMPRA']\n",
    "\n",
    "    # Dividir en conjunto de entrenamiento y prueba\n",
    "    train = product_series[:'2022-12-31']\n",
    "    test = product_series['2023-01-31':'2023-12-31']\n",
    "\n",
    "    try:\n",
    "        # Aplicar Auto ARIMA\n",
    "        stationarity = check_stationarity(train)\n",
    "        model = auto_arima(train, seasonal=stationarity, m=12 if stationarity else 0, trace=True, error_action='ignore', suppress_warnings=True)\n",
    "        models[product_name] = model\n",
    "    except Exception as e:\n",
    "        print(f\"Error al modelar el producto {product_name}: {e}\")\n",
    "\n",
    "# Preparar los datos de prueba y alinearlos con las predicciones\n",
    "test_data = data[(data['AÑO'] == 2023)].copy()\n",
    "\n",
    "# Realizar predicciones y comparar con los datos de prueba\n",
    "for product_name, model in models.items():\n",
    "    if product_name in grouped_data['PRODUCTO'].unique():\n",
    "        # Realizar la predicción\n",
    "        forecast = model.predict(n_periods=10)\n",
    "\n",
    "        # Insertar predicciones en test_data\n",
    "        for i, month in enumerate(range(1, 13)):\n",
    "            test_data.loc[(test_data['PRODUCTO'] == product_name) & (test_data['MES'] == month), 'predicted'] = forecast[i]\n",
    "\n",
    "\n",
    "# Guardar el conjunto de datos de prueba con las predicciones en un archivo CSV\n",
    "test_data.to_csv('../assets/cantidadcompra_predicted.csv', index=False)\n",
    "\n",
    "\n",
    "# WE PREDICT 'PRECIOUNDAD' FOR ALL THE MONTHS OF THE YEAR\n",
    "\n",
    "\n",
    "# Carga de datos\n",
    "data = pd.read_csv('../assets/preciounidad_combinations.csv')\n",
    "\n",
    "# Agrupación de datos por producto y mes\n",
    "grouped_data = data.groupby(['AÑO', 'MES', 'PRODUCTO']).agg({'PRECIOUNIDAD': 'mean'}).reset_index()\n",
    "\n",
    "# Inicializar un diccionario para almacenar los modelos\n",
    "models = {}\n",
    "\n",
    "# Iterar sobre cada producto\n",
    "for product_name in grouped_data['PRODUCTO'].unique():\n",
    "    product_data = grouped_data[grouped_data['PRODUCTO'] == product_name].copy()\n",
    "\n",
    "    # Crear un índice de tiempo combinando año y mes\n",
    "    product_data.loc[:, 'Fecha'] = pd.to_datetime(product_data['AÑO'].astype(str) + '-' + product_data['MES'].astype(str)) + MonthEnd(1)\n",
    "    product_series = product_data.set_index('Fecha')['PRECIOUNIDAD']\n",
    "\n",
    "    # Dividir en conjunto de entrenamiento y prueba\n",
    "    train = product_series[:'2022-12-31']\n",
    "    test = product_series['2023-01-31':'2023-12-31']\n",
    "\n",
    "    try:\n",
    "        # Aplicar Auto ARIMA\n",
    "        stationarity = check_stationarity(train)\n",
    "        model = auto_arima(train, seasonal=stationarity, m=12 if stationarity else 0, trace=True, error_action='ignore', suppress_warnings=True)\n",
    "        models[product_name] = model\n",
    "    except Exception as e:\n",
    "        print(f\"Error al modelar el producto {product_name}: {e}\")\n",
    "\n",
    "# Preparar los datos de prueba y alinearlos con las predicciones\n",
    "test_data2 = data[(data['AÑO'] == 2023) & (data['MES'] <= 10)].copy()\n",
    "\n",
    "# Realizar predicciones y comparar con los datos de prueba\n",
    "for product_name, model in models.items():\n",
    "    if product_name in grouped_data['PRODUCTO'].unique():\n",
    "        # Realizar la predicción\n",
    "        forecast = model.predict(n_periods=10)\n",
    "\n",
    "        # Insertar predicciones en test_data\n",
    "        for i, month in enumerate(range(1, 11)):\n",
    "            test_data2.loc[(test_data2['PRODUCTO'] == product_name) & (test_data2['MES'] == month), 'predicted'] = forecast[i]\n",
    "\n",
    "        # Extraer valores reales para el gráfico\n",
    "        actual_values = test_data2[(test_data2['PRODUCTO'] == product_name) & (test_data2['AÑO'] == 2023)]['PRECIOUNIDAD']\n",
    "\n",
    "\n",
    "# Preparar listas para almacenar todos los valores reales y predichos\n",
    "all_predicted_values = []\n",
    "\n",
    "for product_name in grouped_data['PRODUCTO'].unique():\n",
    "    if product_name in test_data['PRODUCTO'].unique():\n",
    "        predicted_values = test_data2[(test_data2['PRODUCTO'] == product_name) & (test_data2['AÑO'] == 2023)]['predicted']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Guardar el conjunto de datos de prueba con las predicciones en un archivo CSV\n",
    "test_data2.to_csv('../assets/preciounidad_predicted.csv', index=False)\n",
    "\n",
    "predicted_2023['PREDICTED_PRECIOUNIDAD'] = predicted_preciounidad['predicted']\n",
    "predicted_2023['PREDICTED_IMPORTELINEA'] = predicted_partial_2023['PREDICTED_CANTIDADCOMPRA'] * predicted_partial_2023['PREDICTED_PRECIOUNIDAD']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
